{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f81276e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R shape: (31667, 1848) | NaNs: 0 | Infs: 0\n",
      "\n",
      "Saved all recommendations to 'recommendations_top20.csv'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, csc_matrix, issparse \n",
    "\n",
    "class ItemKNNRecommender:\n",
    "    \"\"\"\n",
    "    Item-based kNN CF with:\n",
    "      - user mean-centering\n",
    "      - cosine similarity between items\n",
    "      - optional shrinkage on similarities\n",
    "      - top-k neighbors per item kept as a sparse matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k : int\n",
    "        Number of nearest-neighbor items to keep per item.\n",
    "    shrinkage : float\n",
    "        Similarity shrinkage (>=0). Larger values damp similarities\n",
    "        when co-rating counts are small. sim' = (n_ij/(n_ij+shrink))*sim\n",
    "    \"\"\"\n",
    "    def __init__(self, k=50, shrinkage=100.0):\n",
    "        self.k = int(k)\n",
    "        self.shrinkage = float(shrinkage)\n",
    "        self.user_means_ = None           # (n_users,)\n",
    "        self.S_ = None                    # item-item similarity (csc_matrix)\n",
    "        self.train_ = None                # original ratings CSR\n",
    "        self.n_users_ = 0\n",
    "        self.n_items_ = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def _row_means_csr(X: csr_matrix):\n",
    "        \"\"\"Mean over nonzeros for each row; 0 if a user has no ratings.\"\"\"\n",
    "        counts = np.diff(X.indptr)\n",
    "        sums = np.array(X.sum(axis=1)).ravel()\n",
    "        means = np.zeros(X.shape[0], dtype=np.float32)\n",
    "        nonzero_mask = counts > 0\n",
    "        means[nonzero_mask] = (sums[nonzero_mask] / counts[nonzero_mask]).astype(np.float32)\n",
    "        return means\n",
    "\n",
    "    @staticmethod\n",
    "    def _center_rows_inplace(X: csr_matrix, row_means):\n",
    "        \"\"\"Subtract row_means[u] from each nonzero entry in row u (inplace on a copy).\"\"\"\n",
    "        X = X.copy()  # work on a copy\n",
    "        # For each row, subtract its mean from its slice\n",
    "        for u in range(X.shape[0]):\n",
    "            start, end = X.indptr[u], X.indptr[u+1]\n",
    "            if start < end:\n",
    "                X.data[start:end] -= row_means[u]\n",
    "        return X\n",
    "\n",
    "    @staticmethod\n",
    "    def _topk_by_col(S_csc: csc_matrix, k: int):\n",
    "        \"\"\"Keep top-k absolute values per column of a CSC sparse matrix.\"\"\"\n",
    "        S_csc = S_csc.copy()\n",
    "        n_items = S_csc.shape[0]\n",
    "        for j in range(n_items):\n",
    "            start, end = S_csc.indptr[j], S_csc.indptr[j+1]\n",
    "            col_indices = S_csc.indices[start:end]\n",
    "            col_data = S_csc.data[start:end]\n",
    "            if col_data.size > k:\n",
    "                # Indices of top-k by absolute value\n",
    "                top_idx = np.argpartition(np.abs(col_data), -k)[-k:]\n",
    "                mask = np.zeros(col_data.size, dtype=bool)\n",
    "                mask[top_idx] = True\n",
    "                # Zero out everything else\n",
    "                col_data[~mask] = 0.0\n",
    "                S_csc.data[start:end] = col_data\n",
    "        S_csc.eliminate_zeros()\n",
    "        return S_csc\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit on a user-item rating matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse CSR of shape (n_users, n_items)\n",
    "            Ratings matrix. Zeros/absent entries = no rating.\n",
    "        \"\"\"\n",
    "        if not issparse(X):\n",
    "            X = csr_matrix(np.asarray(X), dtype=np.float32)\n",
    "        else:\n",
    "            X = X.tocsr().astype(np.float32)\n",
    "\n",
    "        self.train_ = X\n",
    "        self.n_users_, self.n_items_ = X.shape\n",
    "\n",
    "        # 1) User mean-centering\n",
    "        self.user_means_ = self._row_means_csr(X)\n",
    "        Xc = self._center_rows_inplace(X, self.user_means_)\n",
    "\n",
    "        # 2) Cosine similarity between item columns: S = (Xc^T Xc) / (||i||*||j||)\n",
    "        # Numerators:\n",
    "        XtX = (Xc.T @ Xc).astype(np.float32)           # square (n_items x n_items) sparse\n",
    "        # Denominator norms:\n",
    "        diag = np.sqrt(XtX.diagonal().clip(min=1e-12)) # item L2 norms\n",
    "        inv_diag = 1.0 / diag\n",
    "        D_inv = csc_matrix((inv_diag, (np.arange(self.n_items_), np.arange(self.n_items_))),\n",
    "                           shape=(self.n_items_, self.n_items_))\n",
    "        S = D_inv @ XtX @ D_inv                        # normalized cosine similarities\n",
    "        S.setdiag(0.0)\n",
    "        S.eliminate_zeros()\n",
    "\n",
    "        # 3) Apply shrinkage using co-rating counts:\n",
    "        Xbin = X.copy()\n",
    "        Xbin.data[:] = 1.0\n",
    "        C = (Xbin.T @ Xbin).astype(np.float32)         # co-rating counts\n",
    "        C.setdiag(0)\n",
    "        if self.shrinkage > 0:\n",
    "            # Align structures for elementwise update: use COO\n",
    "            S = S.tocoo()\n",
    "            # For every nonzero in S, scale by n_ij / (n_ij + shrink)\n",
    "            # Fetch corresponding counts from C\n",
    "            C_coo = C.tocsr()\n",
    "            n_ij = C_coo[S.row, S.col].A.ravel()\n",
    "            factor = n_ij / (n_ij + self.shrinkage)\n",
    "            S.data = S.data * factor.astype(np.float32)\n",
    "            S = S.tocsc()\n",
    "        else:\n",
    "            S = S.tocsc()\n",
    "\n",
    "        # 4) Keep only top-k neighbors per item for efficiency\n",
    "        self.S_ = self._topk_by_col(S, self.k)\n",
    "        return self\n",
    "\n",
    "    def _user_vector(self, u):\n",
    "        \"\"\"Return user's centered ratings as (indices, values).\"\"\"\n",
    "        start, end = self.train_.indptr[u], self.train_.indptr[u+1]\n",
    "        items = self.train_.indices[start:end]\n",
    "        vals = self.train_.data[start:end] - self.user_means_[u]\n",
    "        return items, vals\n",
    "\n",
    "    def predict_one(self, u, i):\n",
    "        \"\"\"\n",
    "        Predict rating for user u on item i.\n",
    "        \"\"\"\n",
    "        if self.S_ is None:\n",
    "            raise RuntimeError(\"Call fit() first.\")\n",
    "        if i < 0 or i >= self.n_items_:\n",
    "            return float(self.user_means_[u])\n",
    "\n",
    "        # neighbors of item i:\n",
    "        start, end = self.S_.indptr[i], self.S_.indptr[i+1]\n",
    "        neigh_idx = self.S_.indices[start:end]\n",
    "        neigh_sim = self.S_.data[start:end]\n",
    "\n",
    "        # items rated by user u:\n",
    "        u_items, u_vals = self._user_vector(u)\n",
    "\n",
    "        # intersect neighbors with user's rated items\n",
    "        # build map for user's items -> centered value\n",
    "        if u_items.size == 0 or neigh_idx.size == 0:\n",
    "            return float(self.user_means_[u])\n",
    "\n",
    "        # intersect via hashing\n",
    "        u_map = dict(zip(u_items.tolist(), u_vals.tolist()))\n",
    "        common_mask = np.array([j in u_map for j in neigh_idx], dtype=bool)\n",
    "        if not common_mask.any():\n",
    "            return float(self.user_means_[u])\n",
    "\n",
    "        sims = neigh_sim[common_mask]\n",
    "        vals = np.array([u_map[j] for j in neigh_idx[common_mask]], dtype=np.float32)\n",
    "\n",
    "        denom = np.abs(sims).sum()\n",
    "        if denom <= 1e-12:\n",
    "            return float(self.user_means_[u])\n",
    "\n",
    "        est = self.user_means_[u] + float((sims @ vals) / denom)\n",
    "        return est\n",
    "\n",
    "    def predict_user(self, u):\n",
    "        \"\"\"\n",
    "        Vectorized predictions for all items for a single user (fast recommend()).\n",
    "        Returns an array of shape (n_items,).\n",
    "        \"\"\"\n",
    "        if self.S_ is None:\n",
    "            raise RuntimeError(\"Call fit() first.\")\n",
    "\n",
    "        mean_u = self.user_means_[u]\n",
    "        # Build a sparse vector of centered ratings for user u: (1 x n_items)\n",
    "        start, end = self.train_.indptr[u], self.train_.indptr[u+1]\n",
    "        cols = self.train_.indices[start:end]\n",
    "        data = self.train_.data[start:end] - mean_u\n",
    "        if cols.size == 0:\n",
    "            return np.full(self.n_items_, mean_u, dtype=np.float32)\n",
    "\n",
    "        r_u_centered = csc_matrix((data, (np.zeros_like(cols), cols)),\n",
    "                                  shape=(1, self.n_items_), dtype=np.float32)\n",
    "\n",
    "        # scores = r_u_centered @ S  (since S is item-item; here we want per-target item)\n",
    "        # But our S_ is csc (cols = target items). We want scores for all target items:\n",
    "        scores = (r_u_centered @ self.S_).toarray().ravel()\n",
    "\n",
    "        # denom per target item = sum |sim(i, j)| over j in items rated by user\n",
    "        # Equivalent to multiply with absolute S restricted to rated items\n",
    "        absS = self.S_.copy()\n",
    "        absS.data = np.abs(absS.data)\n",
    "        denom = (np.abs(r_u_centered) @ absS).toarray().ravel()\n",
    "        \n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            delta = np.zeros_like(scores)\n",
    "            mask = denom > 1e-12\n",
    "            delta[mask] = scores[mask] / denom[mask]\n",
    "        return mean_u + delta\n",
    "\n",
    "    def recommend(self, u, N=10, filter_seen=True):\n",
    "        \"\"\"\n",
    "        Recommend top-N items for user u.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of (item_id, score)\n",
    "        \"\"\"\n",
    "        preds = self.predict_user(u)\n",
    "        if filter_seen:\n",
    "            start, end = self.train_.indptr[u], self.train_.indptr[u+1]\n",
    "            seen = set(self.train_.indices[start:end].tolist())\n",
    "        else:\n",
    "            seen = set()\n",
    "\n",
    "        candidates = [(i, preds[i]) for i in range(self.n_items_) if i not in seen]\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        return candidates[:N]\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import coo_matrix, csc_matrix, csr_matrix, issparse\n",
    "\n",
    "def fit_fast_knn(self, X):\n",
    "    \"\"\"\n",
    "    Faster alternative fit: build item-item top-k graph using sklearn's\n",
    "    NearestNeighbors (cosine) directly, avoiding full XtX.\n",
    "    Includes robust NaN/Inf cleaning.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Ensure CSR float32 and clean any non-finite values up front\n",
    "    if not issparse(X):\n",
    "        X = csr_matrix(np.asarray(X), dtype=np.float32)\n",
    "    else:\n",
    "        X = X.tocsr().astype(np.float32)\n",
    "    if X.data.size:\n",
    "        X.data[~np.isfinite(X.data)] = 0.0\n",
    "\n",
    "    self.train_ = X\n",
    "    self.n_users_, self.n_items_ = X.shape\n",
    "\n",
    "    # --- user mean-centering ---\n",
    "    self.user_means_ = self._row_means_csr(X)\n",
    "    Xc = self._center_rows_inplace(X, self.user_means_)\n",
    "\n",
    "    # Any NaN/Inf after centering? (shouldn't happen, but guard anyway)\n",
    "    if Xc.data.size:\n",
    "        Xc.data[~np.isfinite(Xc.data)] = 0.0\n",
    "\n",
    "    # --- item matrix for cosine kNN ---\n",
    "    # columns = items; normalize columns (L2) so dot == cosine\n",
    "    Xi = Xc.tocsc(copy=True)\n",
    "    if Xi.data.size:\n",
    "        Xi.data[~np.isfinite(Xi.data)] = 0.0\n",
    "    Xi = normalize(Xi, axis=0, norm=\"l2\", copy=False)  # column-wise L2\n",
    "    Xi = Xi.T.tocsr()  # shape: (n_items, n_users)\n",
    "\n",
    "    # --- exact kNN over items (cosine distance) ---\n",
    "    k_eff = min(self.k + 1, self.n_items_)  # +1 for self-neighbor\n",
    "    nn = NearestNeighbors(\n",
    "        n_neighbors=k_eff,\n",
    "        algorithm=\"brute\",\n",
    "        metric=\"cosine\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    nn.fit(Xi)\n",
    "    distances, indices = nn.kneighbors(Xi, return_distance=True)  # (n_items, k_eff)\n",
    "\n",
    "    sims = 1.0 - distances.astype(np.float32)  # cosine sim\n",
    "    sims = sims[:, 1:]                         # drop self\n",
    "    indices = indices[:, 1:]\n",
    "\n",
    "    # --- optional shrinkage ---\n",
    "    if self.shrinkage > 0:\n",
    "        Xbin = self.train_.copy().astype(np.float32)\n",
    "        if Xbin.data.size:\n",
    "            Xbin.data[:] = 1.0\n",
    "        Xbin = Xbin.tocsc()\n",
    "\n",
    "        rows, cols, data = [], [], []\n",
    "        for j in range(self.n_items_):\n",
    "            neigh = indices[j]\n",
    "            if neigh.size == 0:\n",
    "                continue\n",
    "            # co-ratings count n_ij for (j, neigh)\n",
    "            #cj = Xbin[:, j].T @ Xbin[:, neigh]            # 1 x k dense\n",
    "            #n_ij = np.asarray(cj).ravel().astype(np.float32)\n",
    "            # co-ratings count n_ij for (j, neigh)\n",
    "            # (1 x users) @ (users x k) -> (1 x k) dense\n",
    "            cj = (Xbin[:, j].T @ Xbin[:, neigh]).toarray().ravel()\n",
    "            n_ij = cj.astype(np.float32)\n",
    "\n",
    "            shrink_factor = n_ij / (n_ij + self.shrinkage)\n",
    "            s = sims[j] * shrink_factor\n",
    "            rows.extend(neigh.tolist())\n",
    "            cols.extend([j] * len(neigh))\n",
    "            data.extend(s.tolist())\n",
    "        S = coo_matrix((data, (rows, cols)), shape=(self.n_items_, self.n_items_)).tocsc()\n",
    "    else:\n",
    "        rows = indices.ravel()\n",
    "        cols = np.repeat(np.arange(self.n_items_), indices.shape[1])\n",
    "        data = sims.ravel()\n",
    "        S = coo_matrix((data, (rows, cols)), shape=(self.n_items_, self.n_items_)).tocsc()\n",
    "\n",
    "    S.setdiag(0.0)\n",
    "    S.eliminate_zeros()\n",
    "\n",
    "    # safety: keep top-k per column\n",
    "    self.S_ = self._topk_by_col(S, self.k)\n",
    "    return self\n",
    "\n",
    "# ---------------------- Example usage ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    df = pd.read_excel(\"train-1.xlsx\")\n",
    "    # Keep only item columns; replace NaN/±Inf with 0\n",
    "    items_df = df.iloc[:, 1:].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    R = items_df.to_numpy(dtype=np.float32)\n",
    "\n",
    "    print(\"R shape:\", R.shape, \"| NaNs:\", np.isnan(R).sum(), \"| Infs:\", np.isinf(R).sum())\n",
    "    #print(\"Shape of R:\", R.shape)\n",
    "    #print(\"First 5 rows:\\n\", R[:5])\n",
    "    # Monkey-patch or add as a method in your class:\n",
    "    ItemKNNRecommender.fit = fit_fast_knn\n",
    "\n",
    "    model = ItemKNNRecommender(k=50, shrinkage=100).fit(R)\n",
    "    \n",
    "    # --- Recommend top-20 items for all users ---\n",
    "    all_recommendations = {}\n",
    "\n",
    "    for u in range(R.shape[0]):\n",
    "        recs = model.recommend(u, N=20)\n",
    "        all_recommendations[u] = recs  # store (item_id, score) list per user\n",
    "\n",
    "    # --- Optionally, save to a CSV file ---\n",
    "    recommendation_list = []\n",
    "    for u, recs in all_recommendations.items():\n",
    "        for item_id, score in recs:\n",
    "            recommendation_list.append([u, item_id, score])\n",
    "\n",
    "    df_recs = pd.DataFrame(recommendation_list, columns=[\"user_index\", \"item_index\", \"predicted_score\"])\n",
    "    df_recs.to_csv(\"recommendations_top20.csv\", index=False)\n",
    "    print(\"\\nSaved all recommendations to 'recommendations_top20.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your original file (user_index, item_index, predicted_score)\n",
    "df = pd.read_csv(\"recommendations_top20.csv\")\n",
    "\n",
    "# Sort by user and score (just to ensure correct ranking)\n",
    "df = df.sort_values(by=[\"user_index\", \"predicted_score\"], ascending=[True, False])\n",
    "\n",
    "# Group by user and collect top-20 item indices into lists\n",
    "top_items = (\n",
    "    df.groupby(\"user_index\")[\"item_index\"]\n",
    "    .apply(lambda x: x.head(20).tolist())\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Expand each list into separate columns\n",
    "top_items_expanded = top_items[\"item_index\"].apply(pd.Series)\n",
    "top_items_expanded.columns = [f\"item_{i+1}\" for i in range(top_items_expanded.shape[1])]\n",
    "\n",
    "# Combine user_index and the 20 recommended items\n",
    "final_df = pd.concat([top_items[\"user_index\"], top_items_expanded], axis=1)\n",
    "\n",
    "# Save to new CSV\n",
    "final_df.to_csv(\"recommendations_top20_wide.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved to 'recommendations_top20_wide.csv'\")\n",
    "print(final_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
